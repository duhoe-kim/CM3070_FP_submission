{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26ed35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import retro # framework to interact with the game\n",
    "from gym import Env # environment base class\n",
    "from gym.spaces import MultiBinary, Box # space shapes for the game environment\n",
    "\n",
    "import os # for file paths\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np # for calculating frame changes\n",
    "import cv2 as cv # for image prep|rocessing\n",
    "import time # to slow down each frame so we can clearly see the game as it's being played\n",
    "import math # to calculate the reward on each step\n",
    "\n",
    "# Importing the optimzation frame - HPO\n",
    "import optuna\n",
    "\n",
    "# PPO algo for RL\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom environment \n",
    "class StreetFighter(Env): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Specify action space and observation space \n",
    "        self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "        self.action_space = MultiBinary(12)\n",
    "        # Startup and instance of the game \n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis')\n",
    "        \n",
    "        # Starting health in Street Fighter II is 176 HP\n",
    "        self.START_HEALTH = 176\n",
    "        self.REWARD_COEFF = 17\n",
    "        self.PENALTY_COEFF = 1.75\n",
    "        self.LOSS_PENALTY_COEFF = 0.35\n",
    "        \n",
    "        # enemy and player health values that get updated as the game goes along\n",
    "        self.enemy_health = self.START_HEALTH\n",
    "        self.player_health = self.START_HEALTH\n",
    "\n",
    "        # Creating a score variable to hold the player's current score; important for calculating the reward on each step\n",
    "        self.score = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        # Return the first frame \n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs) \n",
    "        self.previous_frame = obs \n",
    "        \n",
    "        # Create a attribute to hold the score delta \n",
    "        self.score = 0\n",
    "        self.enemy_health = self.START_HEALTH\n",
    "        self.player_health = self.START_HEALTH\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def preprocess(self, observation): \n",
    "        # gray scaling from colour\n",
    "        gray = cv.cvtColor(observation, cv.COLOR_BGR2GRAY)\n",
    "        # resize frame from 256*200 to 84*84 for faster processing\n",
    "        resize = cv.resize(gray, (84,84), interpolation=cv.INTER_CUBIC)\n",
    "        # add the channels value\n",
    "        channels = np.reshape(resize, (84,84,1))\n",
    "        return channels \n",
    "    \n",
    "    def step(self, action): \n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        #preprocess state\n",
    "        obs = self.preprocess(obs) \n",
    "        \n",
    "        # get difference of the frames \n",
    "        frame_delta = obs - self.previous_frame\n",
    "        # update previous frame as current frame\n",
    "        self.previous_frame = obs \n",
    "        \n",
    "        # Reshape the reward function\n",
    "         # calculating the change in health for each player (i.e. health from this frame - health from previous frame)\n",
    "        enemy_damage_taken = abs(info['enemy_health'] - self.enemy_health)\n",
    "        player_damage_taken = abs(info['health'] - self.player_health)\n",
    "        \n",
    "        # catching edge cases to make sure no reward\n",
    "        if (self.enemy_health != 0 and info['enemy_health'] == 0 and self.player_health != 0 and info['health'] == 0) or (enemy_damage_taken == 0 and player_damage_taken == 0) or (self.player_health == 0 and self.enemy_health == 0):\n",
    "            reward = 0\n",
    "        \n",
    "        # If the player wins and enemy loses\n",
    "        elif info['enemy_health'] < 0 and info['health'] > 0:\n",
    "            reward = self.START_HEALTH * math.log(info['health'], self.START_HEALTH) * self.REWARD_COEFF\n",
    "            \n",
    "        # if the enemy wins and player loses\n",
    "        elif info['health'] < 0 and info['enemy_health'] > 0:\n",
    "            reward = -math.pow(self.START_HEALTH, (info['enemy_health'] / self.START_HEALTH)) * self.LOSS_PENALTY_COEFF\n",
    "                               \n",
    "        else:\n",
    "            # If the enemy took more damage than the player\n",
    "            if enemy_damage_taken > player_damage_taken:\n",
    "                reward = ((enemy_damage_taken) - (player_damage_taken)) * self.REWARD_COEFF\n",
    "            # If the player took more or same amount of damage than the enemy\n",
    "            else:\n",
    "                reward = ((enemy_damage_taken) - (player_damage_taken)) * self.PENALTY_COEFF\n",
    "\n",
    "        #update current health\n",
    "        self.enemy_health = info['enemy_health']\n",
    "        self.player_health = info['health']\n",
    "        \n",
    "        #update current score to compare with next state\n",
    "        self.score = info['score']\n",
    "            \n",
    "        return frame_delta, reward, done, info\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        self.game.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f136187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return hyperparameters with their range to test \n",
    "def optimize_ppo(trial): \n",
    "    return {\n",
    "        'n_steps':trial.suggest_int('n_steps', 2048, 8192),\n",
    "        'gamma':trial.suggest_loguniform('gamma', 0.8, 0.9999),\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate', 1e-5, 1e-4),\n",
    "        'clip_range':trial.suggest_uniform('clip_range', 0.1, 0.4),\n",
    "        'gae_lambda':trial.suggest_uniform('gae_lambda', 0.8, 0.99)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run optimisation and return mean_reward as the indicator\n",
    "def optimize_agent(trial):\n",
    "    try:\n",
    "        # declare hyperparameters to test\n",
    "        model_params = optimize_ppo(trial) \n",
    "\n",
    "        # create environement with additional wrapper for vectorisation and framing \n",
    "        env = StreetFighter()\n",
    "        env = Monitor(env, LOG_DIR)\n",
    "        env = DummyVecEnv([lambda: env])\n",
    "        env = VecFrameStack(env, 4, channels_order='last')\n",
    "\n",
    "        # create PPO agent model\n",
    "        model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=0, **model_params)\n",
    "        model.learn(total_timesteps=30000)\n",
    "\n",
    "        # evaluate model with 5 episodes\n",
    "        mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=5)\n",
    "        env.close()\n",
    "        \n",
    "        #save the best model\n",
    "        SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(trial.number))\n",
    "        model.save(SAVE_PATH)\n",
    "\n",
    "        return mean_reward\n",
    "    \n",
    "    except Exception as e:\n",
    "        return -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7e3eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = PPO.load('./best_model_30000.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51574666",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './logs/'\n",
    "\n",
    "env = StreetFighter()\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74171a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset game to starting state\n",
    "obs = env.reset()\n",
    "# Set flag to flase\n",
    "done = False\n",
    "\n",
    "\n",
    "prev_player_win = 0\n",
    "player_wins = 0\n",
    "\n",
    "prev_enemy_win = 0\n",
    "enemy_wins = 0\n",
    "\n",
    "rewards = []\n",
    "actions = []\n",
    "    \n",
    "for game in range(1): \n",
    "    while not done: \n",
    "        if done:\n",
    "            enemy_wins = info[0]['enemy_matches_won']\n",
    "            player_wins = info[0]['matches_won']\n",
    "            obs = env.reset()\n",
    "            \n",
    "        env.render()\n",
    "        \n",
    "        action = model.predict(obs)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(0.01)\n",
    "        \n",
    "        rewards.append(reward[0])\n",
    "        actions.append(action[0])\n",
    "        \n",
    "        if prev_player_win > 0 and info[0]['matches_won'] == 0:\n",
    "            prev_player_win = 0\n",
    "            prev_enemy_win = 0\n",
    "        elif prev_enemy_win > 0 and info[0]['enemy_matches_won'] == 0:\n",
    "            prev_player_win = 0\n",
    "            prev_enemy_win = 0\n",
    "        else:\n",
    "            if prev_player_win != info[0]['matches_won']:\n",
    "                player_wins += 1\n",
    "                prev_player_win = info[0]['matches_won']\n",
    "                \n",
    "            if prev_enemy_win != info[0]['enemy_matches_won']:\n",
    "                enemy_wins += 1\n",
    "                prev_enemy_win = info[0]['enemy_matches_won']\n",
    "                \n",
    "        print(reward[0], action[0], player_wins, enemy_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_copy = actions\n",
    "actions_list = []\n",
    "\n",
    "for l in actions_copy:\n",
    "    l_list = l.tolist()\n",
    "    l_list = [round(i) for i in l_list]\n",
    "    \n",
    "    actions_list.append(l_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e13330",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rewards = 0\n",
    "neg_rewards = 0\n",
    "\n",
    "for i in rewards:\n",
    "    if i < 0:\n",
    "        neg_rewards += 1\n",
    "    elif i > 0:\n",
    "        pos_rewards += 1\n",
    "        \n",
    "print(pos_rewards, neg_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_record = pd.DataFrame({\n",
    "    'rewards' : rewards,\n",
    "    'actions' : actions_list\n",
    "})\n",
    "\n",
    "df_record.to_csv('ppo_record.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d161c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame(columns = [\n",
    "    'pos_rewards', 'neg_rewards', 'player_wins', 'enemy_wins'\n",
    "])\n",
    "\n",
    "\n",
    "df_compare.loc[len(df_compare.index)] = [\n",
    "    pos_rewards, neg_rewards, player_wins, enemy_wins\n",
    "] \n",
    "\n",
    "df_compare.to_csv('ppo_compare.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4f28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
